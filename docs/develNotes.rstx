================================
Development notes for GAVO DaCHS
================================

This is basically a heap of stuff I intend to amend with informal docs
on what I'm doing to the software.  While I hope that at some point
it'll grow into a useful introduction to further developing the stuff,
right now it's a random collection that contains quite a bit of
outdated information.  Caveat emptor.

Package Layout
==============

To alleviate cross-import pains, to facilitate later package splitting
and also as a guideline of what goes where, apply the following rules:

* Each functionality block is in a subpackage, the __init__ for which
  contains the main functions, classes, etc., of the the sub-package
  interface most clients will be concerned with.  Clients needing
  special tricks may still import individual modules.
* Within each subpackage, *no* module imports the sub-package, i.e.,
  a module in base never says "from gavo import base"
* A subpackage may have a module common, containing objects that
  multiple modules within that subpackage requires.  common may *not*
  import any module from the subpackage, but may be imported from all
  of them, so in turn it cannot import any module from the subpackage.
* There is a hierarchy of subpackages, where subpackages lower in the
  hierarchy may not import anything from the higher or equal levels, but 
  only from lower levels.  This hierarchy currently looks like this:
  imp < utils < stc < (votable, adql) < base < rscdef < grammars < rsc < svcs <
  registry < protocols < web < rscdesc < (helpers, user)


Error handling, logging
=======================


Exception classes
+++++++++++++++++

It is the goal that all errors that can be triggered from the web or
from within resource descriptors yield sensible error messages with,
if possible, information on the location of the error.  Also, major
operations changing the content of the database should be loggable with
time and, probably, user information.

The core of error processing is utils.excs.  All "sensible" exceptions
(i.e., MemoryErrors and software bugs excepted) should be instances of
gavo.excs.Error (or derived classes).

The base class takes a hint argument at construction that gives 
additional information on how to fix a certain problem.  Apart from
message (in the first argument), the exceptions must always be
constructed using keyword arguments.

When there is structured information (e.g., line numbers, keys, and the
like), always keep the information separate and use the __str__ method
of the exception to construct something humans want to see.  All
built-in exceptions should accept a hint keyword.


The events subsystem
++++++++++++++++++++

All proper DC code (i.e. above base) should do user interaction
through base.ui.notify<something>.  

The <something> can be various things.  base.events defines a class
EventDispatcher (an instance of which then becomes base.ui) that defines
the notify<something> methods.  The docstrings there explain what you're
supposed to pass, and they explain what observers get.

base.events itself does very little with the events, and in particular
it does not do any user interaction -- the idea is that I may yet want
to have Tkinter interfaces or whatever, and they should have a fair
chance to control the user interaction of a program.

The actual action on events is done by observers; these are ususally
defined in ``user``, and some can be selected from the ``gavo`` command
line.  For convenience, you should derive your Observer classes from
base.ObserverBase.  This lets you stuff like::

  from gavo.base import ObserverBase, listensTo

  class PlainUI(ObserverBase):
    @listensTo("NewSource")
    def announceNewSource(self, srcString):
      print "Starting %s"%srcString
	
However, you can also just handle single events by saying things like::

  from gavo import base

  def handleNewSource(srcToken):
    pass
  
  base.ui.subscribeNewSource(handleNewSource)


Catching exceptions
+++++++++++++++++++

In the DC software, is is frequently desirable to ignore the first rule
of exception handling, viz., leave them alone as much as possible.
Instead, we often map exceptions to DC-internal exceptions (this is very
relevant for everything leading up to ValidationErrors).  However, to
keep the original exception information around, whenever you "translate"
an exception, do ``base.ui.notifyExceptionMutation(newException)``.  
This should arrange logging the exception to the error log (although of 
course that's up to the observer selected).

``ui.logOldExc(exc)`` arranges for the notification and returns its
argument, so you can say thing like::

  raise base.ui.logOldExc(GavoError(...))


Testing
=======

Many of the tests will require database connectivity.  They should, in
general, not need resources apart from the availability of a test db
profile.  I have this set up on my private machine like this::

  [profiles]
  test:test

in ~/.gavorc and

::

  database=gavo
  user=msdemlei

in ~/.gavo/etc -- of course, for this to work, you need a postgresql
engine running on your machine with a database gavo in which your role
is superuser (well, has sufficient rights...).

There are doctest, pyunit-based tests, and trial-based tests yaddayadda,


Structures
==========

Resource description within the DC works via instances of
base.Structure.  These parse themselves from XML strings, do validation,
etc.

A complete structure instance has the following callbacks:

* completeElement -- called when the element closing tag is encountered,
  used to fill in computed defaults
* validate -- called after completeElement, used to raise errors if
  some gross ("syntactic") mistakes are in the element
* onElementComplete -- called after validate, i.e., elementCompleted
  can rely on seeing a "valid" structure

In addition, structures can register onParentCompleted callbacks.  These
are called after the elementCompleted of the parent element.

This processing is done automatically when parsing elements from XML.
When building elements manually, you should call the finishElement
method when done to arrange for these methods being called.

If you override these methods, make sure you call the methods of the
superclass.  Since we might, at some point, want mixins to be able
to define validators etc, use super()-based superclass calling, through
_completeElementNext, _validateNext, and _onElementCompleteNext


Metadata
========

Within the framework, there are two main sources of metadata.  For one,
the fields (via datadef.DataField) of a table or a document record carry
metadata on their types, ucds, etc.

Metadata pertaining to other entities than fields is kept with these
entities, viz., ResourceDescriptor, DataDescriptor, DataSet, Table, and
RecordDef, instances.  All these mix in the parsing.meta.MetaMixin
providing getMeta and addMeta methods.

It is the metadata containers' responsibility to choose their parents
and children.  For this purpose, they have have to call a child's
setMetaParent method when they notice a Meta-carrying child is being
added.

Our Metadata implementation has to deal with

* Sequences of metadata -- there may be more than one item for a keyword,
	e.g. for "subject".
* Compound metadata -- items may consist of various sub-items (e.g.,
	coverage, creator)
* There may be sequences of compound objects
* The metadata should be sanely serializable into at least plain text,
	html, and VOResource
* At least XML and key/value pairs should be supported as input
* Handover: Metadata containers are hierarchical -- a service might be
	derived from a data set, which in turn sits within a resource descriptor.
	If the service doesn't have a piece of metadata, it has to hand over
	the question to its parent.  
* To keep the complexity of the meta trees down, we want certain types
  common types of metadata; for example, we generally don't want
  the title to be metadata for a link but rather keep it in the link
  meta value itself.

This results in a rather messy implementation and an interface that's
not really optimal.


Describing Metadata
+++++++++++++++++++

Metadata is organized by mapping keys to values.  Keys are
dot-seperated "atoms" (i.e., sequences of letters); most of them are
defined in RMI.  In addition, the system uses quite a number of
"internal" keys, designated by leading underscores.  They include:

* _type -- on DataSets, this becomes the type attribute of the VOTable.
* _query_status -- on DataSets, this can be used to communicate the
  value of an INFO element in the VOTable (see SIAP spec).  These must
  be meta.InfoItem instances.
* _legal -- human-readable unstructured information on the legal 
  status of the data.
* _infolink -- a URL pointing to further unstructured human-readable
  information to the data content



Getting Metadata
++++++++++++++++

Metadata are accessed by name (or "key", if you will).

The getMeta method usually follows the enclosure hierarchy up, meaning
that if a meta item is not found in the current instance, it will ask
its parent for that item, and so on.  If no parent is known, the meta
information contained in the configuration will be consulted.  If all
fails, a default is returned (which is set via a keyword argument that
again defaults to None) or, if the raiseOnFail keyword argument
evaluates to true, a gavo.NoMetaKey exception is raised.

If you require metadata exactly for the item you are querying, call
getMeta(key, propagate=False).

For metadata that has structure, getMeta will raise a gavo.MetaCardError
when there is more than one matching meta item.  For these, you will
usually use a builder, which will usually be a subclass of
meta.metaBuilder.  web.common.HtmlMetaBuilder is an example of how such
a thing may look like, for simple cases you may get by using
ModelBasedBulder (see the registry code for examples).

The builders are passed to a MetaMixin's buildRepr(metakey, builder)
method that returns whatever the builder's getResult method returns.


Setting Metadata
++++++++++++++++

You can programmatically set metadata on any metadata container by
calling container.addMeta(key, value), where both key and value are
(unicode-compatible) strings.  You can build any hierarchy in this way, 
provided you stick with typeless meta values or can do with the default
types.  Those are set by key in meta._typesForKeys.

To build sequences, call addMeta repeatedly.  To have a sequence of
containers, call addMeta with None or an empty string as value, like 
this:

m.addMeta("p.q", "x")
m.addMeta("p.r", "y")
m.addMeta("p", None)
m.addMeta("p.q", "u")
m.addMeta("p.r", "v")

More complex structures require direct construction of MetaValues.  Use
the makeMetaValue factory for this.  This function takes a value (default
empty), and possibly a key and/or type arguments.  All additional
arguments depend on the meta type desired.

The type argument selects and an entry in the meta._typesForKeys table
that specifies that, e.g., _related meta items always are links.  You
can also give the type directly (which overrides any specification
through a key).

This can look like this:

m.addMeta("info", meta.makeMetaValue("content", type="info",
  infoName="someInfo", infoValue="GIVEN"))


VOTables
========

table.Table instances are primarily meant to be serialized into VOTable
tables.  Since most of the metadata of tables will be contained in the
parent DataSet's docRec, PARAM elements of tables will be taken from
there and will be located in the RESOURCE element that contains the
table(s). 

There's currently no provision for having PARAMS to VOTABLE elements
(these would probably reside in the resource descriptor) or TABLE
elements (this would require a special attribute of table.Table, I
guess).

However, Tables are meta containers and can contain meta information.

With VOTables, correct formatting of values becomes a particular
problem.  While presentation is largely a non-issue, it is paramount
that the literals actually match what the ucds, units and types give.
Therefore, displayHints (apart from "suppress", which by default is
honored) are ignored.  Instead, votable.py defines MapperFactories.
These are just callables taking ColProperties (in a pinch, dicts having
"sufficient" keys will do too, where sufficient at least includes
``ucd``, ``unit``, ``datatype``, ``arraysize``, and ``dbtype``, possibly
more) and returning either None (meaning they won't handle values for
this column) or a callable returning a string.

These MapperFactories are organized in a Registry that can be queried
for a mapper.  If you need to do some special mapping, get a copy of
the default mapper registry by calling ``votable.getMapperRegistry``,
write mappers (a couple of the keys available are listed above, but 
votable calls the mappers with properly filled out votable.ColProperties
instances, so you can, e.g., look at min, max, and hasNulls), and
register them using the ``registerFactory`` method of the registry.  The
mappers will be called in reverse order of registration, so you can
override default behaviour, and you should register the most special
mappers last.

Mapper factories may decide to alter the type they're returning (in
fact, for things like date they'll in all likelihood need to).  To do
that, change the datatype and arraysize attributes.  After the mappers
have run, nothing will look at the dbtype any more.

To add new default mappers, add one in votable.py and call
_registerDefaultMF on them.



User management
===============

The rights model used here is simple: There are users and groups, where
for each user there's a group and vice versa.  Access restrictions are
stated in terms of groups, and users can belong to groups.  Access to a
protected resource is given to any user that belongs to that group.

Users and groups are stored in two database tables generated from
user.vord.  Admittedly, it's overkill to use the gavo framework for
these tables, but there you are.


Memoization
===========

The resourcecache module should be the central point for all kinds of
memoization/caching issues.  To keep dependencies and risks of
recursive imports low, it is the providing modules' responsibility to
register caching functions.  The idea is that, e.g., importparser wants
a cache of resource descriptors.  It should then call

resourcecache.makeCache("getRD", getRD)

Clients would then call

resourcecache.getRD(id).

This mechanism for now is restricted to items that come with a unique
id (the argument).  It would be easy to extend this to multiple-argument
functions, but I don't think that's a good idea -- the "identities" of
the cached objects should be kept simple.

No provision is made to prevent accidental overwriting of function names.

This scheme has the central flaw that you need to make sure that you or
somebody else actually imports the module defining the resource you want
to access.

All caches can be cleared by calling clearCaches.  This only affects
caches make via makeCache.  There probably should be similar mechanisms
for other shared resources, since we want to be able to respond to
"reload"-like requests.




Profiling
=========

If you want to profile server actions, try a script like this::

  """
  Make a profile of server responses.

  Call as

  trial --profile createProfile.py
  """

  import sys

  from gavo import api
  from gavo.web import dispatcher

  sys.path.append("/home/msdemlei/gavo/trunk/tests")

  import trialhelpers



  class ProfileThis(trialhelpers.RenderTest):
    renderer = dispatcher.ArchiveService()

    def testOneService(self):
      self.assertGETHasStrings("/ppmx/res/ppmx/scs/form",
        {"hscs_pos": "12 2", "hscs_sr": "20.0"},
        ["PPMX"])

After running, you can use pstats on the file profile.data.

To profile actually running GAVO operations, use the --profile <profile
file> option of the gavo program.  For the server, you must make sure
in cleanly exists in order to have meaningful stats.  Do this by
accessing /exit on a debug server.


Delimited SQL identifiers
=========================

Although it may look like it, we do not really support delimited
identifiers (DIs) as column names (and not at all as table names).  I happen
to regard them as an SQL misfeature and really only want to keep them
out of my software.

However, TAP forces me to deal with them at least superficially.  That
means, using them elsewhere will lead to lots of mysterious error
messages from inside the DC software bowels.  There still should not be
any remote exploits possible when using them.

Here's the deal on them:

They are represented as utils.misctricks.QuotedName objects.  These
QuotedNames have some methods to control the impact the partial support
for delimited identifiers has on the rest of the software.  In
particular, when you stringify them, they  result in string ready for
inclusion into SQL (i.e., hopefully properly escaped).  The hash to the
name, i.e., there are no implied quotes, and, unfortunately,
hash(di)!=hash(str(di)).

The DC software right now assumes DIs are ASCII only (what do the
standards people say?).

The one real painful thing is the representation of result rows with
DIs -- I did not want to have lots of these ugly QuotedNames in the
result rows, so they end up as SQL-escaped strings when used as keys.
This is extra sad since in this way for a DI column foo,
rec[QName("foo")] raises a KeyError.  To work around this, fields have
a key attribute, and rec[f.key] should never bomb.
